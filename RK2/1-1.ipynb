{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в данных:\n",
      "work_year             0\n",
      "experience_level      0\n",
      "employment_type       0\n",
      "job_title             0\n",
      "salary                0\n",
      "salary_currency       0\n",
      "salary_in_usd         0\n",
      "employee_residence    0\n",
      "remote_ratio          0\n",
      "company_location      0\n",
      "company_size          0\n",
      "dtype: int64\n",
      "\n",
      "Названия столбцов в данных:\n",
      "Index(['work_year', 'experience_level', 'employment_type', 'job_title',\n",
      "       'salary', 'salary_currency', 'salary_in_usd', 'employee_residence',\n",
      "       'remote_ratio', 'company_location', 'company_size'],\n",
      "      dtype='object')\n",
      "\n",
      "Размеры X и y:\n",
      "(88584, 10) (88584,)\n",
      "Обучаем линейную регрессию...\n",
      "Обучение завершено.\n",
      "Обучаем градиентный бустинг...\n",
      "Обучение завершено.\n",
      "Linear Regression MSE: 8027132101.067358, R2: -0.45337942798027764\n",
      "Gradient Boosting MSE: 10131554.336249944, R2: 0.9981655973191457\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "data = pd.read_csv('salaries.csv')\n",
    "\n",
    "print(\"Пропуски в данных:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\nНазвания столбцов в данных:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Заполнение пропусков\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "data['salary_in_usd'] = imputer.fit_transform(data[['salary_in_usd']])\n",
    "\n",
    "# Размерности\n",
    "X = data.drop(columns=['salary_in_usd']) \n",
    "y = data['salary_in_usd']  # Целевая переменная\n",
    "\n",
    "print(\"\\nРазмеры X и y:\")\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение числовых и категориальных столбцов\n",
    "numeric_features = ['work_year', 'salary', 'remote_ratio']  \n",
    "categorical_features = ['experience_level', 'employment_type', 'job_title', \n",
    "                        'salary_currency', 'employee_residence', \n",
    "                        'company_location', 'company_size']  \n",
    "\n",
    "# Преобразование числовых и категориальных признаков\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Линейная регрессия\n",
    "lr_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Градиентный бустинг\n",
    "gb_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "print(\"Обучаем линейную регрессию...\")\n",
    "lr_model.fit(X_train, y_train)\n",
    "print(\"Обучение завершено.\")\n",
    "\n",
    "print(\"Обучаем градиентный бустинг...\")\n",
    "gb_model.fit(X_train, y_train)\n",
    "print(\"Обучение завершено.\")\n",
    "\n",
    "# Прогнозы\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Оценка качества моделей\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Вывод метрик\n",
    "print(f\"Linear Regression MSE: {mse_lr}, R2: {r2_lr}\")\n",
    "print(f\"Gradient Boosting MSE: {mse_gb}, R2: {r2_gb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE (Среднеквадратичная ошибка)\n",
    "Что это?\n",
    "MSE измеряет среднеквадратичное отклонение предсказанных значений от реальных. Это показывает, насколько сильно предсказания модели отклоняются от фактических значений.\n",
    "\n",
    "Почему использовал?\n",
    "\n",
    "MSE является важной метрикой для регрессионных задач, так как она показывает, насколько ошибка модели велика. Чем меньше значение MSE, тем лучше модель предсказывает.\n",
    "\n",
    "Для линейной регрессии MSE составил 8,027,132,101.07, что является очень высоким значением и указывает на то, что модель плохо справляется с предсказаниями.\n",
    "\n",
    "Для градиентного бустинга MSE составил 10,131,554.34, что значительно ниже, и модель показывает гораздо лучшие результаты.\n",
    "\n",
    "\n",
    "R² (Коэффициент детерминации)\n",
    "Что это?\n",
    "R² — это метрика, показывающая, какая доля вариации зависимой переменной объясняется моделью. Он измеряет, насколько хорошо модель предсказывает результат по сравнению с базовой моделью, которая предсказывает только среднее значение.\n",
    "\n",
    "\n",
    "Почему использовал?\n",
    "R² позволяет понять, насколько хорошо модель объясняет данные. Высокое значение R² свидетельствует о том, что модель эффективно улавливает закономерности в данных.\n",
    "\n",
    "Результат:\n",
    "Для линейной регрессии R² составил -0.453, что означает, что модель объясняет менее половины вариации в данных и не лучше, чем простое среднее значение. Это указывает на плохую модель.\n",
    "Для градиентного бустинга R² составил 0.998, что практически идеально, и говорит о том, что модель отлично объясняет данные.\n",
    "\n",
    "Линейная регрессия:\n",
    "Результаты линейной регрессии с высоким MSE и отрицательным R² говорят о том, что модель плохо справляется с задачей. Это может быть связано с тем, что данные имеют сложные, нелинейные зависимости, которые линейная регрессия не может уловить.\n",
    "Важно отметить, что линейная регрессия эффективна только в случае, если существует линейная зависимость между признаками и целевой переменной. В данном случае модель не смогла бы объяснить вариацию данных, что подтверждается отрицательным значением R².\n",
    "\n",
    "Градиентный бустинг:\n",
    "Результаты градиентного бустинга с низким MSE и высоким R² показывают, что эта модель значительно лучше справляется с задачей. Она эффективно объясняет данные и может находить сложные закономерности, что делает ее более подходящей для таких задач, чем линейная регрессия.\n",
    "Показатель R² близкий к 1 указывает на то, что градиентный бустинг практически идеально объясняет вариацию в данных, что делает модель отличным выбором для этой задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
